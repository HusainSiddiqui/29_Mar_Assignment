{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression, or L1 regularization, is a linear regression technique that incorporates a penalty term in the objective function to improve model performance and feature selection. It differs from other regression techniques, such as Ordinary Least Squares (OLS) regression and Ridge Regression, in the following ways:\n",
    "\n",
    "1. Penalty term: Lasso Regression adds the L1 norm of the coefficient vector to the loss function. The L1 norm is the sum of the absolute values of the coefficients. This penalty term encourages the model to shrink less important coefficients to zero, effectively performing feature selection. In contrast, Ridge Regression uses the L2 norm (sum of squared coefficients) as the penalty term, which shrinks the coefficients towards zero but does not set them exactly to zero.\n",
    "\n",
    "2. Feature selection: Lasso Regression has the ability to select relevant features by setting the coefficients of irrelevant features to zero. This makes Lasso Regression particularly useful when dealing with high-dimensional datasets with many potentially irrelevant predictors. Ridge Regression, on the other hand, does not force coefficients to exactly zero, allowing all predictors to contribute to the model.\n",
    "\n",
    "3. Sparsity: Due to the feature selection property, Lasso Regression tends to produce sparse solutions where only a subset of predictors have non-zero coefficients. This can simplify the model interpretation by identifying the most important predictors. In contrast, Ridge Regression typically retains all predictors with non-zero coefficients, which may complicate the interpretation.\n",
    "\n",
    "4. Bias-variance trade-off: Lasso Regression can be more sensitive to multicollinearity compared to Ridge Regression. In the presence of highly correlated predictors, Lasso Regression tends to select one of them while setting others to zero. This can lead to a higher bias but lower variance. In contrast, Ridge Regression shrinks all coefficients but does not force any to zero, striking a balance between bias and variance.\n",
    "\n",
    "Overall, Lasso Regression is a powerful regression technique that provides automatic feature selection and can handle high-dimensional datasets. It is particularly useful when interpretability and sparsity are desired, and when there is a need to identify the most relevant predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the main advantages of using Lasso Regression for feature selection:\n",
    "\n",
    "1. Automatic feature selection: Lasso Regression performs feature selection by setting the coefficients of irrelevant features to zero. This eliminates the need for manual feature selection or expert knowledge about the dataset. Lasso Regression considers the data and determines which features are most important for predicting the target variable.\n",
    "\n",
    "2. Sparse solutions: Lasso Regression tends to produce sparse solutions, where only a subset of predictors have non-zero coefficients. This sparsity property can simplify the model and improve interpretability by identifying the most important predictors. It allows you to focus on a smaller set of relevant features rather than considering all predictors.\n",
    "\n",
    "3. Handling high-dimensional data: Lasso Regression is particularly useful when dealing with datasets that have a high number of predictors compared to the number of observations (high-dimensional data). In such cases, it can effectively reduce the dimensionality by identifying and selecting a subset of relevant features, thus reducing the risk of overfitting and improving model generalization.\n",
    "\n",
    "4. Dealing with multicollinearity: Lasso Regression can handle multicollinearity (high correlation among predictors) by selecting one predictor among a group of highly correlated predictors and setting others to zero. This helps to mitigate the issues caused by multicollinearity and avoids the problem of including redundant information in the model.\n",
    "\n",
    "By leveraging these advantages, Lasso Regression provides a powerful and efficient way to perform feature selection, improving model performance, interpretability, and generalization in various applications and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients of a Lasso Regression model follows a similar approach to interpreting coefficients in other regression models. However, due to the nature of Lasso Regression and its ability to perform feature selection, there are a few specific considerations to keep in mind. Here's how you can interpret the coefficients of a Lasso Regression model:\n",
    "\n",
    "1. Magnitude: The magnitude of the coefficients represents the strength of the relationship between each predictor variable and the response variable. Larger coefficient magnitudes indicate a stronger influence on the response variable. In Lasso Regression, the magnitude of the coefficients can vary widely, as some coefficients may be exactly zero (indicating that the corresponding feature is not selected).\n",
    "\n",
    "2. Sign: The sign (+/-) of the coefficients indicates the direction of the relationship between the predictor variable and the response variable. A positive coefficient suggests a positive relationship, meaning an increase in the predictor leads to an increase in the response. Conversely, a negative coefficient suggests a negative relationship, indicating that an increase in the predictor leads to a decrease in the response.\n",
    "\n",
    "3. Feature selection: In Lasso Regression, the coefficients of irrelevant features are forced to zero, effectively performing feature selection. This means that if a coefficient is exactly zero, it indicates that the corresponding feature does not contribute to the model prediction. Therefore, you can interpret a coefficient of zero as an indication that the corresponding feature is not relevant for predicting the response variable.\n",
    "\n",
    "4. Relative importance: Comparing the magnitudes of non-zero coefficients within the same Lasso Regression model can provide an indication of the relative importance of different predictors. Higher magnitude coefficients relative to others suggest relatively more influential predictors in the model.\n",
    "\n",
    "5. Interpretation within the context: As with any regression model, it is important to interpret the coefficients within the specific context of the dataset and the problem domain. Consider the units of measurement for the predictors and the response variable and how the coefficients relate to meaningful changes in the response variable.\n",
    "\n",
    "6. Comparisons between models: When comparing different Lasso Regression models with varying values of the regularization parameter (lambda), pay attention to the changes in coefficient magnitudes and signs. The feature selection capability of Lasso Regression can lead to different sets of selected features and different coefficient values between models.\n",
    "\n",
    "By considering these aspects, you can interpret the coefficients of a Lasso Regression model and gain insights into the relationships between predictors and the response variable, while also accounting for feature selection and model sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lasso Regression, there is typically one main tuning parameter that can be adjusted: the regularization parameter, often denoted as lambda (λ). The regularization parameter controls the amount of regularization applied to the model and determines the trade-off between fitting the training data well and keeping the coefficients small.\n",
    "\n",
    "By adjusting the regularization parameter in Lasso Regression, you can control the level of shrinkage applied to the coefficients. A higher value of lambda increases the amount of regularization, leading to more coefficients being driven towards zero and increasing the sparsity of the model. Conversely, a lower value of lambda decreases the amount of regularization, allowing coefficients to have larger magnitudes and reducing sparsity.\n",
    "\n",
    "Here's how the regularization parameter affects the performance of the Lasso Regression model:\n",
    "\n",
    "1. Model complexity: The regularization parameter acts as a penalty term that discourages complex models by shrinking the coefficients towards zero. A higher value of lambda increases the penalty, resulting in a simpler model with fewer non-zero coefficients. This helps to prevent overfitting and can improve the model's ability to generalize to unseen data.\n",
    "\n",
    "2. Feature selection: Lasso Regression has the ability to perform feature selection by setting the coefficients of irrelevant features to exactly zero. The regularization parameter controls the degree of feature selection. As lambda increases, more features are likely to have their coefficients shrink to zero, effectively removing them from the model. Lower values of lambda may result in more features being retained, potentially leading to a more complex model with more predictors.\n",
    "\n",
    "3. Bias-variance trade-off: Adjusting the regularization parameter in Lasso Regression influences the bias-variance trade-off. Higher values of lambda introduce more bias into the model, reducing the chance of overfitting but potentially increasing the underfitting. Lower values of lambda reduce bias but may lead to higher variance and increased risk of overfitting.\n",
    "\n",
    "4. Interpretability: As lambda increases, the coefficients in Lasso Regression tend to be smaller, making them more interpretable. This is because higher regularization encourages more coefficients to be driven towards zero, resulting in a sparser model with fewer predictors. A sparser model with fewer predictors can be easier to interpret and explain.\n",
    "\n",
    "5. Performance on test data: The performance of the Lasso Regression model on test data can be affected by the choice of lambda. It is important to select an optimal value of lambda that balances model complexity, feature selection, and generalization performance. This is typically done through techniques like cross-validation or using an evaluation metric on a validation set.\n",
    "\n",
    "By tuning the regularization parameter in Lasso Regression, you can control the complexity, sparsity, and interpretability of the model, while also influencing its generalization performance and ability to handle overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression is primarily designed for linear regression problems, where the relationship between the predictors and the response variable is assumed to be linear. However, Lasso Regression can also be extended to handle non-linear regression problems through a process called feature engineering.\n",
    "\n",
    "In non-linear regression, you can transform the predictor variables to introduce non-linearities. This can be achieved by applying mathematical transformations such as polynomial transformations, logarithmic transformations, exponential transformations, or interaction terms. By creating these non-linear transformations of the predictors, you can capture non-linear relationships between the predictors and the response variable.\n",
    "\n",
    "Once the predictor variables have been transformed, you can then apply Lasso Regression to the transformed data. The Lasso Regression model will estimate the coefficients of the transformed predictors and perform feature selection, effectively selecting the most relevant transformed predictors for the non-linear regression problem.\n",
    "\n",
    "Here's an example to illustrate the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate non-linear data\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y = np.sin(X) + np.random.normal(0, 0.1, (100, 1))\n",
    "\n",
    "# Apply polynomial feature transformation\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Fit Lasso Regression model\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_poly, y)\n",
    "\n",
    "# Predict on new data\n",
    "X_new = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "X_new_poly = poly.transform(X)\n",
    "y_pred = lasso.predict(X_new_poly)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the original data\n",
    "plt.scatter(X, y, color='blue', label='Original Data')\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(X_new, y_pred, color='red', label='Predicted Values')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Lasso Regression - Non-linear Regression')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between Ridge Regression and Lasso Regression:\n",
    "\n",
    "| Aspect              | Ridge Regression             | Lasso Regression             |\n",
    "|---------------------|------------------------------|------------------------------|\n",
    "| Regularization Term | L2 penalty: λ * Σ(w^2)        | L1 penalty: λ * Σ(|w|)       |\n",
    "| Objective Function  | Loss function + L2 penalty    | Loss function + L1 penalty    |\n",
    "| Selection of Variables | Keeps all variables and shrinks their coefficients towards zero | Can shrink coefficients of less important variables to zero, effectively performing variable selection |\n",
    "| Dealing with Multicollinearity | Handles multicollinearity by reducing the impact of correlated variables through coefficient shrinkage | Handles multicollinearity by selecting one variable from a set of highly correlated variables and setting the coefficients of others to zero |\n",
    "| Solution Stability  | More stable solution, less sensitive to small changes in data or model parameters | Less stable solution, more sensitive to small changes in data or model parameters |\n",
    "| Interpretation of Coefficients | Coefficients represent the strength of the relationship between predictors and the response, but their magnitudes may be reduced due to regularization | Coefficients represent the strength and direction of the relationship between predictors and the response, and their magnitudes may be reduced or set to zero due to regularization |\n",
    "| Computational Complexity | Computationally efficient for high-dimensional data | Computationally intensive, especially for large datasets with many predictors |\n",
    "| Selection Bias       | No inherent selection bias | May introduce some selection bias due to variable selection |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity in the input features to some extent. \n",
    "\n",
    "Here's how Lasso Regression handles multicollinearity:\n",
    "\n",
    "1. Coefficient shrinkage: Lasso Regression applies a penalty term (L1 norm) to the sum of absolute values of the coefficients in the objective function. This penalty term encourages the model to shrink less important coefficients towards zero. In the presence of multicollinearity, where there is high correlation among predictors, Lasso Regression tends to select one predictor from a correlated group and sets the coefficients of the remaining predictors to zero. By doing so, it effectively reduces the impact of multicollinearity by choosing the most important predictor and discarding the redundant ones.\n",
    "\n",
    "\n",
    "2. Feature selection: The key advantage of Lasso Regression in the presence of multicollinearity is its ability to perform feature selection. It automatically identifies and selects the most relevant predictors by setting the coefficients of irrelevant predictors to zero. By eliminating redundant predictors, Lasso Regression reduces the multicollinearity issue and focuses on the most informative predictors for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value of the regularization parameter (lambda) in Lasso Regression is typically chosen through a process called cross-validation. Cross-validation involves dividing the data into multiple subsets or folds, training the Lasso Regression model on a subset of the data, and evaluating its performance on the remaining fold. This process is repeated for different values of lambda, and the value that yields the best performance is selected as the optimal lambda."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
